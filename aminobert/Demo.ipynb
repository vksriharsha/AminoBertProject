{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expose AminoBERT's last encoder layer hidden states to the RGN\n",
    "\n",
    "Goal is to do this outside of the tf.Estimator API.\n",
    "\n",
    "We do this in cell 10.\n",
    "\n",
    "The rest of the notebook is validating that this new implementation outputs the exact same results as before by numerically checking previously generated outputs for Round 6 CASP14 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import subprocess\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from Bio import SeqIO\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../')\n",
    "import modeling\n",
    "import tokenization\n",
    "import optimization\n",
    "import run_finetuning_and_prediction\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with tf.Estimator interface\n",
    "\n",
    "The guts of this are not important. Including here as this is what I've been using to inference seqs for CASP. We'll validate our Estimator-free reimplementation produces the same output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(seqs, qfunc, checkpoint_file, wt_log_prob_mat=None, \n",
    "                   return_seq_log_probs=True, return_seq_output=True, \n",
    "                   clip_seq_level_outputs=True):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    MAX_SEQ_LENGTH = 1024\n",
    "    output_dir = '../../data/test/'\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    tokenizer=tokenization.FullTokenizer(k=1, token_to_replace_with_mask='X')\n",
    "\n",
    "    result = run_finetuning_and_prediction.run_model(\n",
    "        input_seqs=list(seqs),\n",
    "        labels=qfunc,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        tokenizer=tokenizer,\n",
    "        bert_config_file='AminoBERT_config_v2.json',\n",
    "        output_dir=output_dir,\n",
    "        init_checkpoint=checkpoint_file,\n",
    "        do_training=False, # No fine-tuning\n",
    "        do_evaluation=False,\n",
    "        do_prediction=True, # Prediction only.\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=5e-5,\n",
    "        warmup_proportion=0.1,\n",
    "        train_batch_size=16,\n",
    "        eval_batch_size=32,\n",
    "        predict_batch_size=32,\n",
    "        use_tpu=False,\n",
    "        return_seq_log_probs=return_seq_log_probs,\n",
    "        return_seq_output=return_seq_output, # encoder_layers[-1]\n",
    "        encoding_layer_for_seq_rep=[[0,1,2,3], [4,5,6,7], [8,9,10,11]],\n",
    "        wt_log_prob_mat=wt_log_prob_mat,\n",
    "        clip_seq_level_outputs=clip_seq_level_outputs\n",
    "    )\n",
    "    \n",
    "    end = time.time()    \n",
    "    result['compute_time'] = end - start\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPEND_M = True\n",
    "DATA_DIR = 'round_6/'\n",
    "\n",
    "CHECKPOINT = os.path.join('checkpoint',\n",
    "        'AminoBERT_runs_v2_uniparc_dataset_v2_5-1024_fresh_start_model.ckpt-1100000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_read(fasta_file):\n",
    "    headers = []\n",
    "    seqs = []\n",
    "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "        headers.append(seq_record.id)\n",
    "        seqs.append(str(seq_record.seq))\n",
    "    \n",
    "    return headers, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['round_6/T1088.fa',\n",
       " 'round_6/T1075.fa',\n",
       " 'round_6/T1072s1.fa',\n",
       " 'round_6/T1082.fa',\n",
       " 'round_6/T1085.fa',\n",
       " 'round_6/T1089.fa',\n",
       " 'round_6/T1073.fa',\n",
       " 'round_6/T1070.fa',\n",
       " 'round_6/T1079.fa',\n",
       " 'round_6/T1083.fa',\n",
       " 'round_6/T1078.fa',\n",
       " 'round_6/T1077.fa',\n",
       " 'round_6/T1087.fa',\n",
       " 'round_6/T1084.fa',\n",
       " 'round_6/T1086.fa',\n",
       " 'round_6/T1074.fa',\n",
       " 'round_6/T1071.fa',\n",
       " 'round_6/T1080.fa',\n",
       " 'round_6/T1076.fa',\n",
       " 'round_6/T1090.fa']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences being removed due to length: 0\n",
      "Sequences being removed: [] []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MDGKFTLGAGVGVVEHPYKQYDADVYPVPVISYESENFWFHGLGGGYYLWNDTNDKLSITAYWSPMYFKPGDSDSEQMRRLDKRKSTVMAGLSYVHNTPYGFLRTTIAGDTLDNSNGINWDLAWLYRYTNGNLTLTPGIGVEWNSDNQNEYYYGVSRHESRRSGMRSYDPDSSWNPYLELSANYRFLGDWSVYGVARYTRLSDEITDSPMVDKSWSGLISTGITYTF*',\n",
       " 'METEQPEETFPNTETNGEFGKRPAEDMEEEQAFKRSRNTDEMVELRILLQSKNAGAVIGKGGKNIKALRTDYNASVSVPDSSGPERILSISADIETIGEILKKIIPTLEEGLQLPSPTATSQLPLESDAVECLNYQHYKGSDFDCELRLLIHQSLAGGIIGVKGAKIKELRENTQTTIKLFQECCPHSTDRVVLIGGKPDRVVECIKIILDLISESPIKGRAQPYDPNFYDETYDYGGFTMMFDDRRGRPVGFPMRGRGGFDRMPPGRGGRPMPPSRRDYDDMSPRRGPPPPPPGRGGRGGSRARNLPLPPPPPPRGGDLMAYDRRGRPGDRYDGMVGFSADETWDSAIDTWSPSEWQMAYEPQGGSGYDYSYAGGRGSYGDLGGPIITTQVTIPKDLAGSIIGKGGQRIKQIRHESGASIKIDEPLEGSEDRIITITGTQDQIQNAQYLLQNSVKQYSGKFF*',\n",
       " 'MGSMGLYFSSLDSSIDILQKRAQELIENINKSRQKDHALMTNFRNSLKTKVSDLTEKLEERIYQIYNDHNKIIQEKLQEFTQKMAKISHLETELKQVCHSVE*',\n",
       " 'MKKFIFATIFALASCAAQPAMAGYDKDLCEWSMTADQTEVETQIEADIMNIVKRDRPEMKAEVQKQLKSGGVMQYNYVLYCDKNFNNKNIIAEVVGE*',\n",
       " 'MVILAKYNVEKDAAAKKSQAEKLEKNLLLGIENAEKSKDASLLVAAQDDYLQNSVLKQKSFDVQYQKTYAIYQKGDYAVAADQLKQLALNPQGSAAIRTQAAELSLDALALLKDDARIMAWSAEYAGKFADKKADFQQIQQKSILTQSAKLAESQPEQALAALGSFHAASASAEDRKVYLKNKILLSEKLNKITEARVAIEDLLREKTLTAEEREFALGRKVWFAELELDFATALKTAEQMNFAGLSADDKVLKLAMYSELADKDPQQYYAQYLKQSKDDSKKPLIASQLIRLSKNPVKDLETYKMYFKSNNGLYARAALEVYGRTKDRKALDLALKEKGASKQDAFVMIEKIVFLADLKALSAPLMAQTIDTKNQNTIAQGLKARVKLLEKAEALANRAINTGDWSSQLLALDLVARENTRFYNEALSLPMPSGLTPEQENEYLTILSQQVAPNQNTAMMAETKVKEFWAQTGALESYKAFATQNTEWAQYTSQEVEAVAAIAPEAQKATWTAAVAQIKAEESAQTKPTLVELEKARTHLKQNPFMASAIEEALVLEKKAQRKSMVEYLEGRLATLAKKDTEVKEKQQ*',\n",
       " 'MDDNVNDFRPVPYPDEVVGLNPDPDFEPIWEIASPTITVFSSKASNDISYRVPAIAVTKKGSILVFCEARYGTWQDKAGRTDILMKRSTDKGITWTEKNLTNQATSSKLSYMDPTVVVDQVTGKIFLFTSLWDAVGKESAKQGYNNRAIMYTSEDDGLNWTRKDLTDEVEIGIFSGATRMIGSFGPGSGVQMTSSEQYKNRLIVPIRTFKVNEAAGTVSNGGNTAMWSDDNGGTWETGQPNKSGEWMVTEAPDGALIGNIRYNGHRQNYVSTDGGAKWPSFSDYDPIALPTPAKGCAGSVIVKDGWMYYCGAKGIIETTAHDDRGILYLAKAKFFGGHSHTFDPADHMVLYDKAAGYTCMALLPDGDMAIVAELGNEPGFQKLSTRPAEWMRLELFILSTKKPL*',\n",
       " 'MGDFVSNQFGALLKNKLEEIQKKNPRFSFRSLAKKVGISPGCLNELMHGKRPLSEFYANKIVLGLELGAEERNEVYSLISTRSRKFAAQKTLAEKELELIASWEHFAILNLIRMKTFKPEPEWIAERLALPLEKVQQSLELLLDLGFIKRKGNSIARSVASLATTTDIPSEALVQAHVSDMHKAIEVLKRTPIDRRDYSAITMAINPHKMEEAKNLIKKFRRKFSMLVEEGDMTEVYNLNIQFFPLTVTESEKPL*',\n",
       " 'MANKPTQPLFPLGLETSESSNIKGFNNSGTIEHSPGAVMTFPEDTEVTGLPSSVRYNPDSDEFEGYYENGGWLSLGGGGIRWETLPHAPSSNLLEGRGYLINNTTGTSTVVLPSPTRIGDSVTICDAYGKFATYPLTVSPSGNNLYGSTEDMAITTDNVSATFTWSGPEQGWVITSGVGLGQGRVYSREIFTQILASETSAVTLNTPPTIVDVYADGKRLAESKYSLDGNVITFSPSLPASTELQVIEYTPIQLGNGGGSGSSTITWVYNGGSAIGGETEITLDIVVDDVPAIDINGSRQYKNLGFTFDPLTSKITLAQELDAEDEVVVIINGTP*',\n",
       " 'MELVRLMGFLTVLSLALSANAQNSKDYLVVVDRIPVSELRWVMTQSGDHGVNAKSYWSDSMEQTFLVDPLNPTLRNQASVNYLRLLQNVSTGIVDPALVGVDVKLTKKKFPTALELETALAAAGQNPNVLLESMSPQSPQYLALRDSLRKLNNACVNNLWPALPKVKKTLKLGSKDAILIPLKTRMTQLGYPMTSLDNVFDDKVVAAVNDIQWNLRFKPDSKISPGGKTWKYLNVSCQDRMRQIRLDMEKLRWFPQHFEDRYIFINLAMSYFSLVDKSGGGFYSMSFRTINGRPERKSPTMKDKIVYIVINPFWVVPPTIFREDKVEEIKNLWPWEIREYFDTRHYQVWNKSFTQRFDPASIDWYNMDPNQDANIYIRQSPHRMNALGSLKFMMTNSYAIYLHDTNQRELFAEPHRLLSSGCVRVEKPVDLAEYLLKGTEWDRAAIERYMAKPGEVLDKDTKVQLKQQMPVYMVFLTSQLSSDGILRFAEDSYRQGTRLLRLGAW*',\n",
       " 'MGAMGSEIEHIEEAIANAKTKADHERLVAHYEEEAKRLEKKSEEYQELAKVYKKITDVYPNIRSYMVLHYQNLTRRYKEAAEENRALAKLHHELAIVED*',\n",
       " 'MAAPTPADKSMMAAVPEWTITNLKRVCNAGNTSCTWTFGVDTHLATATSCTYVVKANANASQASGGPVTCGPYTITSSWSGQFGPNNGFTTFAVTDFSKKLIVWPAYTDVQVQAGKVVSPNQSYAPANLPLEHHHHHH*',\n",
       " 'MSISGQAGKEYTNIGVGFGTESTGLALSGNWTHNDDDGDVAGVGLGLNLPLGPLMATVGGKGVYTNPNYGDEGYAAAVGGGLQWKIGNSFRLFGEYYYSPDSLSSGIKSYEEANAGARYTIMRPVSIEAGYRYLNLSGKDGNRDNAVADGPYVGVNASF*',\n",
       " 'MGAMEVVPAPEHPANISAPATSPTEHQEAAALHKKHAEHHKGMAVHHESVAAEYGKAGHPELKKHHEAMAKHHEALAKEHEKAAENHEKMAKPK*',\n",
       " 'MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH*',\n",
       " 'MKKGLLIFSMTMGVAAAPHAMASGSTQDLLIQKLTQVQLGLAPADPARAAVLLRLADLHAERSRQLSMKELADGCTVCTAGAKDRDKALTYYTEALSKVPPTSVAKVHLQMGHLYELQGRNDLAEKSYQAMLTNGGMTTPIEMAEANLSLAEMAFRQSDFAKAAGLYDKVLATEGASSQGLAAYRRAWCSFRQGNMDASIAQLQDILKNPKLQSRMAASRGVADVQFLEEVSRDMATFMAARGIKDGDAETLYSLSPEQFKLQQVTMLAREGLRLGQKDQALKTWDYVYQKQSDPKMRLEAQVRMAQLNFDLKNTQAAAKSYQTALGLWGATDCTTATCEESAKGLRQFIVGWNRLENSKPSAELLTAYQEYFQVFAEDEDMYVWGAQAAATAGNYVLASQWTALANK*',\n",
       " 'MRLLSKPKPLEGSFFMVRLSVRIGWHRGPFLAGTGFGVKGTKQGNTMKNMFGKILASTLLLSSISASAGGNDFVSRLKALDGREGKIVSSYDDENTGRCRLELQKYELEDGSQGLAVYLQDTGMYFTPSAGLDKETKLKDANTAVVSTSSERPGGDACGDFGGALGYKKVLVLKDNQVTIRETFRCVMDGFKKYDLSTTCQF*',\n",
       " 'MQSLAKLLVIEDDAAIRLNLSVILEFVGEQCEVIESTQIDQINWSAVWGGCILGSLRGQALSEQLIQSLTKANHIPLLVANKQPYSLEEFPNYVGELDFPLNYPQLSDALRHCKEFLGRKGFQVLATARKNTLFRSLVGQSMGIQEVRHLIEQVSTTEANVLILGESGTGKEVVARNIHYHSGRRNGPFVPINCGAIPAELLESELFGHEKGAFTGAITARKGRFELAEGGTLFLDEIGDMPMSMQVKLLRVLQERCFERVGGNSTIKANVRVIAATHRNLEEMIDGQKFREDLYYRLNVFPIEMPALRDRIDDIPLLLQELMTRMEAEGAQPICFTPRAINSMMEHDWPGNVRELANLVERMVILYPNSLVDVNHLPTKYRYSDIPEFQPEPSRFSSVEEQERDVLEGIFAEDFNFEEPQEFVPDIDAPQALPPEGVNLKELLADLEVNLINQALEAQGGVVARAADMLGMRRTTLVEKMRKYNMQR*',\n",
       " 'MKNLIPSLFLILSGVAVQAASPSPGPLFTYEGLLTDAGSTAITTTQTVQLQIIYPASCVVFEETHSITPGSSGEFSVIVGSGTRTDSTGNTADRIFASSGNVTCADTSSVVASGFTTRSLRVRVGGTDLTPDVAINTVPFAINAARLADKTATDFVQISASTTQANADSVFSRYNTLNSVLNLFATPGTNGQLLIGTGTGYTPATLTAGSGINITNGSGSITISASGGGGSVTSVTALSPLVVGGTAAVPEIALPQANSTTNGFLSSTDWQAFNNKQNKTLSSGNIWVGNVVGSAAEVSVSGDATLNSSGVLSLANVGTAGTYAKVTTDAKGRVTSGSALTAADIPSLDWSKITSGLPATLGGYGISDAVKNMGGSPSIQSGTDAARPAPGTAGRIYISSDTNQIYRDTGSAWNTLGGGGGAALPISLTTEVTGILPIANGGTGSSSVAGAMSALSPLSTKGDLLVHNGTANVRLPAGASGQVLAADTTDANGVKWVTAPAGTVTAVTGNAPVMVSNNTTTPLISVSDATTSTKGVVQIGNGLNVTSGTVSVNPGSFPSVVPVTKGGTGTGTFNANKLVYTNASGSAFTEFACGIGMAIAFDGTGIAGCSSYSSLGVIVNSGNSLGIPMAVGTNDAFSLSFETNNTPRMTIDDVGRVGVGTTAPTSALHVIGTGEVARFVTSATGGVVIDSTALNYNPSLIYRKTNINRWSMMVNAASETGGNAGSNLSILRYDDTGATLGAAVTIDRASGFFGINTAAPAYNIHVTGTAGLSTGSAWTVASDARLKDVHGDYEFGLSEILKLHTVRYNYKKDNAAKIPSDVPMVGFIAQEVQQVIPDAVKTRADGYLELNVDPIHWATVNAVKELHGMCKATEEQLNTITRRVSSLEEDAAVKDLRIKALEDENKNLKKDLELIKAKLGLQ*',\n",
       " 'MSSEVDGATLIARSLKQQGIDHLFGVVGFPITAIAAAAQKEGVAYLGMRNEQSAAYAAAAYGYLTGRPGAAVVVTGPGVVHGLSGLANAQQNCWPMILIGGASETYRGGMGAFQEERQVLIASPFCKFAHGIESVARIPFYVEMATRNAIYGRPGATYLDMPDDIIRGTCETDKIAQAERVPEAPRSVAPAENVEAALDLLEKAQRPLVLLGKGMAWSRGEDEVRAFIERTQVPFVRSPMGKGVMPDDHPLSASAARTLALQQADVIFLMGARLNWIFHFGLPPRYAKDVKVIQLDIAPEEIGHNKPTEVALVGDGKAIMAQLNKALVNRQWFHPKDTPWRQALTKKAAENVATIKPQVDDDQGPAGYYRALRDVAAWMPKNAILSAEGAGTMDIGLTQLASSNARSVLNAGTYGTMGVGLGQAIAAAVSDPSRPVIHLSGDSAIGFSGMEMETLVRYNLPVKIVVLNNGGIGPGMPEIPENPMFNLKPNALIYGARYDKVMEAFGGKGIFVKEPKDIRKALDEAMAFKGPALVNVVLSQGSTRKAQQFAWHS*',\n",
       " 'MHHAHGTENLYFQGSAATMAAQSLLSIPVEYRSQVWCRANLPYPPAPQLPIPAVVDILTKASQALPQISFSWTLIDQPPDGSLFLVWQAPTLPSPPDGMHFMSNERFFNMDVAGKVLEIHEAKHGFYPLSETRTMHVRCRYRLLGVGFDNFWLVHYFQGSETDSIPANISVAKPPHLRRYPLPDVKTSPFLLQE*']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228, 464, 103, 98, 590, 405, 256, 336, 506, 100, 139, 160, 95, 74, 409, 203, 489, 923, 554, 195]\n"
     ]
    }
   ],
   "source": [
    "# Sequences to predict structures for. 1 sequence per fasta.\n",
    "fastas = glob.glob(os.path.join(DATA_DIR, '*.fa'))\n",
    "print(len(fastas))\n",
    "display(fastas)\n",
    "\n",
    "# Read in sequences.\n",
    "headers, seqs = zip(*[fasta_read(f) for f in fastas])\n",
    "\n",
    "# Add a stop char to each sequence to be consistent\n",
    "# with how the model was trained.\n",
    "headers = [h[0] for h in headers]\n",
    "seqs = [s[0] + '*' for s in seqs]\n",
    "\n",
    "# Prepend an M. Again reflective of how the model\n",
    "# was trained.\n",
    "if PREPEND_M:\n",
    "    for i in range(len(seqs)):\n",
    "        if seqs[i][0] != 'M':\n",
    "            seqs[i] = 'M' + seqs[i]\n",
    "            \n",
    "# Remove sequences that are too long for the model\n",
    "mask = np.array([len(s) for s in seqs]) <= 1023\n",
    "print('Sequences being removed due to length:', np.sum(~mask))\n",
    "print('Sequences being removed:', np.array(headers)[~mask], np.array(seqs)[~mask])\n",
    "\n",
    "seqs = list(np.array(seqs)[mask])\n",
    "headers = list(np.array(headers)[mask])\n",
    "fastas = list(np.array(fastas)[mask])\n",
    "\n",
    "# Take a look at the seqs\n",
    "display(seqs)\n",
    "print([len(s) for s in seqs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing input\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f466378c9d8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f466378bb70>, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_is_chief': True, '_model_dir': '../../data/test/', '_num_worker_replicas': 1, '_master': '', '_service': None, '_keep_checkpoint_max': 5, '_device_fn': None, '_save_checkpoints_steps': 3, '_log_step_count_steps': None, '_task_type': 'worker', '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=200, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_save_checkpoints_secs': None, '_tf_random_seed': None, '_cluster': None, '_evaluation_master': '', '_global_id_in_cluster': 0, '_task_id': 0, '_save_summary_steps': 100, '_eval_distribute': None, '_train_distribute': None, '_protocol': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: ../../data/test/, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 1024)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 1024)\n",
      "INFO:tensorflow:  name = labels, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 1024)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (27, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (1, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (2048, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (27,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = fine_tuning/output_weights:0, shape = (1, 768)\n",
      "INFO:tensorflow:  name = fine_tuning/output_bias:0, shape = (1,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "qfunc = np.random.randn(len(seqs)) # dummy labels. Ignore this.\n",
    "inf_result = run_prediction(seqs, qfunc, CHECKPOINT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinarily, save the contextual embeddings\n",
    "\n",
    "But we won't do that here just to double check we can reproduce the results I generated in my other repo and handed off to Ratul & Mohammed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print('Writing numpy arrays')\n",
    "for j in range(len(seqs)):\n",
    "    assert inf_result['predict']['seq_output'][j].shape[0] == len(seqs[j])\n",
    "    assert headers[j] in fastas[j], (headers[j], fastas[j])\n",
    "\n",
    "    outfile = fastas[j] + '.npy'\n",
    "    np.save(outfile, inf_result['predict']['seq_output'][j])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contextual embeddings are contained in `inf_result['predict']['seq_output']`\n",
    "\n",
    "**IMPORTANT:** Instead of returning the full (max_seq_len=1024, 768) matrix of encoder outputs, we clip the encoder output to include only those token embeddings that correspond to the protein sequence.\n",
    "\n",
    "So, the CLS output is clipped off, as well as all outputs after the sequence stop char.\n",
    "\n",
    "Hence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(seqs)):\n",
    "    assert inf_result['predict']['seq_output'][j].shape[0] == len(seqs[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check this tf.Estimator inference matches the previous tf.Estimator  inference I did in my other repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(seqs)):\n",
    "    prev_result = np.load(fastas[i] + '.npy')\n",
    "    \n",
    "    assert np.allclose(inf_result['predict']['seq_output'][i], prev_result)\n",
    "    print(np.amax(inf_result['predict']['seq_output'][i] - prev_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool moving code over to this new repo didn't affect anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-implementation without tf.Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1024\n",
    "BERT_CONFIG_FILE = 'AminoBERT_config_v2.json'\n",
    "USE_ONE_HOT_EMBEDDINGS = False\n",
    "TOKENIZER = tokenization.FullTokenizer(k=1)\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_ids = tf.placeholder(tf.int32, shape=(None, MAX_SEQ_LENGTH), name='input_ids')\n",
    "input_mask = tf.placeholder(tf.int32, shape=(None, MAX_SEQ_LENGTH), name='input_mask')\n",
    "token_type_ids = tf.placeholder(tf.int32, shape=(None, MAX_SEQ_LENGTH), name='token_type_ids')\n",
    "y_true = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "model = modeling.BertModel(\n",
    "    config=bert_config,\n",
    "    is_training=False,\n",
    "    input_ids=input_ids,\n",
    "    input_mask=input_mask,\n",
    "    token_type_ids=token_type_ids,\n",
    "    use_one_hot_embeddings=USE_ONE_HOT_EMBEDDINGS)\n",
    "\n",
    "### Add RGN here ###\n",
    "# e.g. rgn(model.sequence_output)\n",
    "\n",
    "## Initialize from checkpoint\n",
    "(assignment_map, initialized_variable_names) = (\n",
    "        modeling.get_assignment_map_from_checkpoint(\n",
    "                tf.trainable_variables(), CHECKPOINT)\n",
    ")\n",
    "\n",
    "# Replaces variable initializers such that the initialize from the checkpoint\n",
    "# when we call tf.global_variables_initializer()\n",
    "tf.train.init_from_checkpoint(CHECKPOINT, assignment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep sequence input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = run_finetuning_and_prediction.check_seqs(\n",
    "        seqs, max_seq_length=MAX_SEQ_LENGTH) \n",
    "\n",
    "input_dict = run_finetuning_and_prediction.generate_input_features_from_seq_list(\n",
    "        seqs, None, TOKENIZER, pad_to=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "    # Initialize variables. Do random initialization or init from checkpoint.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    feed_dict = {\n",
    "        input_ids: np.array(input_dict['input_ids']),\n",
    "        input_mask: np.array(input_dict['input_mask']),\n",
    "        token_type_ids: np.array(input_dict['segment_ids']),\n",
    "    }\n",
    "    \n",
    "    seq_out_new = sess.run(model.sequence_output, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1024, 768)\n"
     ]
    }
   ],
   "source": [
    "print(seq_out_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the sequence level output (hidden states from last encoder layer) contains hidden state vectors for all 1024 token positions. In order to compare to the results generated above, we'll need to trim to keep only vectors corresponding to residues in our seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(seq_out_new.shape[0]):\n",
    "    \n",
    "    so_clip = seq_out_new[i][1:(len(seqs[i])+1),:] # Exclude CLS token\n",
    "    \n",
    "    assert np.allclose(so_clip, inf_result['predict']['seq_output'][i])\n",
    "    print(np.amax(so_clip - inf_result['predict']['seq_output'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our manually exposed sequence outputs match the ones generated when we run the inference through the tf.Estimator API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
